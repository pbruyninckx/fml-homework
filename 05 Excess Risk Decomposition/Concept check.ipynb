{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excess Risk Decomposition\n",
    "\n",
    "## Notes to self: Excess risk theory reminder\n",
    "\n",
    "Ideally we'd like to find the Bayes decision function that minimises risk\n",
    "$$\n",
    "f^* = \\arg \\min_f \\mathbb E(l(x | y))\n",
    "$$\n",
    "\n",
    "However to keep optimisation feasible (and add some regularisation) we only look for functions within an hypothesis space $\\mathbb F$.\n",
    "$$\n",
    "f^\\mathbb F = \\arg \\min_{f \\in \\mathbb F} \\mathbb E (l(x | y))\n",
    "$$\n",
    "\n",
    "The difference between these is the **approximation error**\n",
    "$$\n",
    "R(f^\\mathbb F) - R(f^*)\n",
    "$$\n",
    "\n",
    "However in general we can't compute $f^\\mathbb F$, as we only have a limited number of data. As such we can only compute the **empirical risk minimiser**\n",
    "$$\n",
    "\\hat{f_n} = \\arg \\min \\frac{1}{n} \\sum_{i=1}^n l\\left(f(x_i), y_i\\right)\n",
    "$$\n",
    "\n",
    "This introduces the **estimation error**.\n",
    "$$\n",
    "R(\\hat{f_n}) - R(f^\\mathbb F)\n",
    "$$\n",
    "\n",
    "However, because when trying to find $\\hat{f_n}$, the optimisation algorithm doesn't give the perfect result, but it yields a result $\\tilde{f_n}$. Thus we also get an **optimisation error**\n",
    "$$\n",
    "R(\\tilde{f_n}) - R(\\hat{f_n})\n",
    "$$\n",
    "\n",
    "The **Excess Risk** is the difference between the final risk, and the risk of the Bayes decision function\n",
    "$$\n",
    "R(\\tilde{f_n}) - R(f^*) \\\\\n",
    "= \\underbrace{R(f^\\mathbb F) - R(f^*)}_{\\text{Approximation Error}} \n",
    "  + \\underbrace{R(\\hat{f_n}) - R(f^\\mathbb F)}_{\\text{Estimation Error}}\n",
    "  + \\underbrace{R(\\tilde{f_n}) - R(\\hat{f_n})}_{\\text{Optimisation Error}}\n",
    "$$\n",
    "\n",
    "### Some notes\n",
    "\n",
    "* The approximation error and the estimation error are always positive.\n",
    "* The optimisation error could be negative\n",
    "* If the approximation error and estimation error dominate the optimisation error (which seems to be quite often the case),\n",
    "  there is no point in using advanced optimisation methods to minimise the optimisation error,\n",
    "  as it will have a negligable effect on the total excess risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Concept Check Questions\n",
    "\n",
    "### Exercise 1: Uniform distribution with $X=Y$\n",
    "\n",
    "#### (a) Bayes risk\n",
    "\n",
    "Bayes risk is 0.\n",
    "\n",
    "#### (b) Approx error when using constant functions\n",
    "\n",
    "In this case\n",
    "$$f^\\mathbb F = \\mathbb E[X] = 5.5$$.\n",
    "Then the approximation error becomes\n",
    "$$\n",
    "R(f^\\mathbb F) = \\frac{1}{10}\\sum_{x=1}^{10}(x-5.5)^2 = 8.25\n",
    "$$\n",
    "\n",
    "#### (c) Hypothesis space of affine functions\n",
    "\n",
    "The approximation error will be 0.\n",
    "\n",
    "When $\\hat{f}(x) = x + 1$,\n",
    "$$\n",
    "R(\\hat f) - R(f_\\mathcal F) = 1^2 = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Characterise in terms of error\n",
    "\n",
    "#### (a) Overfitting\n",
    "\n",
    "Estimation error\n",
    "\n",
    "#### (b) Underfitting\n",
    "\n",
    "Most likely to be approximation error. However in some cases it might maybe be caused by optimisation error\n",
    "\n",
    "#### (c) Computationally intractable precise empirical risk minimisation\n",
    "\n",
    "I would be tempted to say that this one is going to be optimisation error.\n",
    "\n",
    "#### (d) Not enough data\n",
    "\n",
    "Likely to cause an estimation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Brain teasers\n",
    "\n",
    "#### (a) Randomness of $R(\\hat f_n)$\n",
    "$R(\\hat f_n)$ depends on the chosen training data. If we assume the training data to be fixed, this will be deterministic. However if we train using randomly selected/generated data, it will be considered random.\n",
    "\n",
    "#### (b) Increasing hypothesis space\n",
    "**False**: Increasing the hypothesis space will not always leave $R(\\hat f_n)-R(f^*)$ constant. For a counter example have a look at a situation like exercise 1, where switching from constant functions to affine functions will (in most but the most extreme cases) decrease $R(\\hat f_n)-R(f^*)$.\n",
    "\n",
    "#### (c) Data as a random sample\n",
    "**False**: When we treat the data as a random sample, the approximation error will still be deterministic, as it doesn't depend on the data. However the estimation error, as it depends on the actual data used, will indeed be random\n",
    "\n",
    "#### (d) Empirical risk of ERM\n",
    "**False**  The risk we try to minimise for on our training data will generally be smaller than the true risk.\n",
    "\n",
    "#### (e) Implicit sample space\n",
    "\n",
    "1. Sample space of the test set to compute $\\hat R$\n",
    "2. Sample space to compute the different training sets to compute $\\hat f_n$\n",
    "3. Sample space is again the training data set. Note that for minibatch gradient descent the other aspect of the sample space is which training data are chose for which batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Brain teasers ct'd (comparisons)\n",
    "\n",
    "(a) More training data should yield a smaller estimation error. Although given that it's only five more data points I expect the result to be negligible and somewhat random.\n",
    "\n",
    "(b) Approximation error $f_1 \\geq$ approximation error $f_2$.\n",
    "\n",
    "(c) Approximation error $f_1 \\geq$ approximation error $f_2$. Note that there might be a risk of overfitting.\n",
    "\n",
    "(d) I think the estimation error in the second case will be larger, as there's more freedom, and thus more data needed to get an equally well fit.\n",
    "\n",
    "(e) Unknown. it might be improving, or there might be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Haven't seen decision trees (yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 3: Concept Check Questions\n",
    "\n",
    "1. $$\\lambda = \\frac{1}{C}$$\n",
    "2. \n",
    "3. \n",
    "2. The norm of the regularised parameters will always be smaller, given that large parameters are penalised, as the specific goal of the regularisation term is to minimise the size of the parameters. (Note: the model solution here is much more formal; I quite like the approach, and I would never have thought of it myself.)\n",
    "3. Feature normalisation ensures that the 'regularisation force' applied to each of the parameters is equally large. If we would expect the different features to have greatly different sizes, the matching parameters would also have values differing in order of magnitude, and the large parameters would be much more affected by regularisation than the smaller parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
